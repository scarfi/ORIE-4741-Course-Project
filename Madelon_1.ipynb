{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Nothing to be done\n",
      "INFO: METADATA is out-of-date — you may not have the latest version of LowRankModels\n",
      "INFO: Use `Pkg.update()` to get the latest versions of your packages\n",
      "INFO: Nothing to be done\n",
      "INFO: METADATA is out-of-date — you may not have the latest version of DataFrames\n",
      "INFO: Use `Pkg.update()` to get the latest versions of your packages\n",
      "INFO: Checking out LowRankModels master...\n",
      "INFO: Pulling LowRankModels latest master...\n",
      "INFO: No packages to install, update or remove\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"LowRankModels\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.checkout(\"LowRankModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using LowRankModels\n",
    "using DataFrames\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Madelon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = readtable(\"Madelon.csv\", header = false);\n",
    "nobs = nrow(df)\n",
    "nfeatures = ncol(df)-1\n",
    "\n",
    "Madelon = Array(Any,nrow(df),ncol(df))\n",
    "\n",
    "for row = 1:nrow(df)\n",
    "    for col = 1:ncol(df)\n",
    "        Madelon[row,col] = df[row,col]\n",
    "    end\n",
    "end\n",
    "\n",
    "Madelon[:,1:500] = Madelon[:,1:500]/200;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert Labels to Booleans\n",
    "Madelon_Labels = Madelon[:,501]\n",
    "Madelon_Labels = convert(Array{Bool}, Madelon[:,501])\n",
    "\n",
    "for row = 1:nrow(df)\n",
    "    Madelon[row,501] = Madelon_Labels[row]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set observed values\n",
    "PropObserved = .9\n",
    "\n",
    "obs = Array{Tuple{Int64,Int64}}(round(Int,(nobs*nfeatures) + nobs*PropObserved))\n",
    "ind = 1\n",
    "\n",
    "#Mark all features as observed\n",
    "for row = 1:nobs\n",
    "    for col = 1:nfeatures\n",
    "        obs[ind] = (row,col) \n",
    "        ind = ind+1\n",
    "    end\n",
    "end\n",
    "\n",
    "#Mark top PropObserved of labels as observed\n",
    "for row = 1:round(Int,PropObserved*nobs)\n",
    "    obs[ind] = (row,round(Int, nfeatures+1))\n",
    "        ind = ind+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LowRankModels.WeightedHingeLoss(10000.0,LowRankModels.BoolDomain(),1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weighted Hinge Loss\n",
    "WHL = scale!(HingeLoss(), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = Loss[QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),QuadLoss(),\n",
    "        QuadLoss(),QuadLoss(),WHL];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit GLRM to Data\n",
    "m,n,k = nobs,nfeatures+1,250\n",
    "\n",
    "rx = ZeroReg()\n",
    "ry = ZeroReg()\n",
    "glrm = GLRM(Madelon,losses,rx,ry,k,obs = obs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GLRM\n",
      "Iteration 10: objective value = 1.643790273615818e8\n",
      "Iteration 20: objective value = 4.8325997865329824e7\n",
      "Iteration 30: objective value = 3.361381379754008e7\n",
      "Iteration 40: objective value = 2.7434254620538406e7\n",
      "Iteration 50: objective value = 1.8328134800837573e7\n",
      "Iteration 60: objective value = 1.1693814468596697e7\n",
      "Iteration 70: objective value = 8.43739252041022e6\n",
      "Iteration 80: objective value = 5.327322108542401e6\n",
      "Iteration 90: objective value = 4.1523547668411615e6\n",
      "Iteration 100: objective value = 2.518536503052086e6\n"
     ]
    }
   ],
   "source": [
    "params = ProxGradParams(5,max_iter = 100)\n",
    "X, Y, ch = fit!(glrm, params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600×501 Array{Float64,2}:\n",
       " -1.19431    3.11779    2.62546    …  3.57909  -0.663154  -271.397   \n",
       "  2.30151    2.49076    2.56093       2.73134   2.40614     -6.99349 \n",
       "  2.38093    2.48452    2.96189       2.9636    1.95789     -0.998134\n",
       "  3.31151   -0.662004  -0.408635      5.22415   1.95765      0.884871\n",
       "  2.48018    2.30821    2.53264       2.48829   2.59026     10.0525  \n",
       "  2.51127    2.2752     2.18892    …  2.35365   2.60254      9.14605 \n",
       "  2.46549    2.25612    2.37665       2.55239   2.46783     10.2747  \n",
       "  2.40285    2.33401    3.13219       2.56821   2.45885     -1.00369 \n",
       "  2.67244    2.21711    2.44068       2.48017   2.51333     10.1572  \n",
       "  2.48601    2.36674    2.93531       2.78614   2.37334     -1.0017  \n",
       "  2.02325    2.20469    0.0449145  …  3.8187    3.98051     -0.982896\n",
       " -0.025505   2.44029   -0.0112163     2.29535  -0.994891  -194.128   \n",
       "  2.44308    2.35868    2.70425       2.4596    2.48086      3.01926 \n",
       "  ⋮                                ⋱                         ⋮       \n",
       "  2.48071    2.32942    2.49413       2.48942   2.57806      2.42746 \n",
       "  2.54365    2.4417     2.35329       2.56454   2.36441      1.6962  \n",
       "  2.39208    2.35402    2.39252    …  2.69663   2.41331      1.97716 \n",
       "  2.44205    2.4566     2.23293       2.55914   2.55039      1.5187  \n",
       "  2.45836    2.32774    2.69696       2.58923   2.36291      1.32954 \n",
       "  2.26501    2.28822    3.00163       2.56015   2.25249      1.55022 \n",
       "  2.26872    2.44198    2.404         2.56545   2.43448      2.08609 \n",
       "  2.44401    2.36035    2.58067    …  2.57599   2.50744      1.91392 \n",
       "  2.36176    2.46609    2.37061       2.43623   2.23084      1.74176 \n",
       "  2.57623    2.51796    2.69653       2.46179   2.54779      1.5775  \n",
       "  2.37904    2.3914     2.60465       2.797     2.44299      2.2177  \n",
       "  2.54327    2.15544    2.53326       2.60694   2.60667      1.36499 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X'*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600×501 Array{Number,2}:\n",
       " -1.19431    3.11779    2.62546    4.86109  …  3.57909  -0.663154  false\n",
       "  2.30151    2.49076    2.56093    2.43108     2.73134   2.40614   false\n",
       "  2.38093    2.48452    2.96189    1.37746     2.9636    1.95789   false\n",
       "  3.31151   -0.662004  -0.408635   4.73853     5.22415   1.95765    true\n",
       "  2.48018    2.30821    2.53264    2.3326      2.48829   2.59026    true\n",
       "  2.51127    2.2752     2.18892    2.52043  …  2.35365   2.60254    true\n",
       "  2.46549    2.25612    2.37665    2.34002     2.55239   2.46783    true\n",
       "  2.40285    2.33401    3.13219    2.47021     2.56821   2.45885   false\n",
       "  2.67244    2.21711    2.44068    2.43284     2.48017   2.51333    true\n",
       "  2.48601    2.36674    2.93531    2.51613     2.78614   2.37334   false\n",
       "  2.02325    2.20469    0.0449145  2.74608  …  3.8187    3.98051   false\n",
       " -0.025505   2.44029   -0.0112163  3.39533     2.29535  -0.994891  false\n",
       "  2.44308    2.35868    2.70425    2.37607     2.4596    2.48086    true\n",
       "  ⋮                                         ⋱                          ⋮\n",
       "  2.48071    2.32942    2.49413    2.50092     2.48942   2.57806    true\n",
       "  2.54365    2.4417     2.35329    2.45914     2.56454   2.36441    true\n",
       "  2.39208    2.35402    2.39252    2.47651  …  2.69663   2.41331    true\n",
       "  2.44205    2.4566     2.23293    2.26229     2.55914   2.55039    true\n",
       "  2.45836    2.32774    2.69696    2.4185      2.58923   2.36291    true\n",
       "  2.26501    2.28822    3.00163    2.41278     2.56015   2.25249    true\n",
       "  2.26872    2.44198    2.404      2.32929     2.56545   2.43448    true\n",
       "  2.44401    2.36035    2.58067    2.43636  …  2.57599   2.50744    true\n",
       "  2.36176    2.46609    2.37061    2.48961     2.43623   2.23084    true\n",
       "  2.57623    2.51796    2.69653    2.39184     2.46179   2.54779    true\n",
       "  2.37904    2.3914     2.60465    2.44562     2.797     2.44299    true\n",
       "  2.54327    2.15544    2.53326    2.39385     2.60694   2.60667    true"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yimp = impute(glrm.losses,glrm.X'*glrm.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600×501 Array{Any,2}:\n",
       " 2.425  2.385  2.685  2.395  2.26   …  2.405  2.395  2.375  2.48   false\n",
       " 2.415  2.29   2.3    2.435  2.935     2.415  2.46   2.55   2.585  false\n",
       " 2.435  2.71   2.495  2.34   2.24      2.4    2.445  2.495  2.49   false\n",
       " 2.4    2.455  2.55   2.425  2.475     2.375  2.41   2.47   2.305   true\n",
       " 2.42   2.51   2.64   2.445  2.33      2.405  2.52   2.475  2.555   true\n",
       " 2.405  2.48   2.255  2.4    2.58   …  2.41   2.315  2.285  2.5     true\n",
       " 2.42   2.665  2.49   2.33   2.885     2.395  2.375  2.31   2.42    true\n",
       " 2.37   2.34   2.99   2.45   2.65      2.4    2.505  2.645  2.445  false\n",
       " 2.42   2.49   2.79   2.445  2.54      2.29   2.365  2.655  2.2     true\n",
       " 2.48   2.24   2.85   2.38   2.385     2.39   2.43   2.91   2.48   false\n",
       " 2.39   2.23   2.285  2.375  2.34   …  2.355  2.505  2.75   2.585  false\n",
       " 2.43   2.395  2.64   2.415  2.65      2.375  2.48   2.525  2.425  false\n",
       " 2.33   2.43   2.7    2.46   2.5       2.365  2.465  2.53   2.61    true\n",
       " ⋮                                  ⋱                                  ⋮\n",
       " 2.41   2.13   2.385  2.45   2.725     2.365  2.48   2.66   2.56    true\n",
       " 2.39   2.51   2.27   2.445  2.33      2.41   2.435  2.615  2.52   false\n",
       " 2.405  2.285  2.535  2.49   2.515  …  2.35   2.475  2.665  2.255  false\n",
       " 2.43   2.545  2.12   2.405  2.615     2.405  2.4    2.59   2.195   true\n",
       " 2.41   2.295  2.8    2.47   2.61      2.385  2.6    2.56   2.24   false\n",
       " 2.375  2.45   3.085  2.435  2.855     2.375  2.485  2.68   2.135  false\n",
       " 2.36   2.335  2.42   2.34   2.27      2.37   2.475  2.69   2.46    true\n",
       " 2.465  2.29   2.515  2.39   2.585  …  2.37   2.445  2.53   2.53    true\n",
       " 2.405  2.42   2.405  2.45   2.245     2.405  2.45   2.275  2.255   true\n",
       " 2.425  2.425  2.65   2.4    2.22      2.39   2.405  2.42   2.585   true\n",
       " 2.385  2.345  2.64   2.425  2.415     2.35   2.45   3.065  2.46    true\n",
       " 2.41   2.265  2.575  2.405  2.5       2.37   2.47   2.68   2.63   false"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Madelon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ImpResults = Yimp[2341:2600,501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260-element Array{Any,1}:\n",
       " false\n",
       " false\n",
       "  true\n",
       " false\n",
       "  true\n",
       " false\n",
       " false\n",
       "  true\n",
       "  true\n",
       " false\n",
       " false\n",
       "  true\n",
       " false\n",
       "     ⋮\n",
       "  true\n",
       " false\n",
       " false\n",
       "  true\n",
       " false\n",
       " false\n",
       "  true\n",
       "  true\n",
       "  true\n",
       "  true\n",
       "  true\n",
       " false"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RealResults = Madelon[2341:2600,501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.5115384615384615"
      ],
      "text/plain": [
       "0.5115384615384615"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success = 0\n",
    "for i = 1:length(ImpResults)\n",
    "    if ImpResults[i] == RealResults[i]\n",
    "        success = success + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "success/length(ImpResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3,4,true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Int64,1}:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
